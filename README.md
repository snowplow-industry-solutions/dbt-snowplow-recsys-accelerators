[![early-release]][tracker-classification] 
[![Release][release-image]][releases]
[![License][license-image]][license] 

![snowplow-logo](https://raw.githubusercontent.com/snowplow/dbt-snowplow-utils/main/assets/snowplow_logo.png)

# dbt-snowplow-recommendations

This dbt package extracts the relevant data from the Snowplow Ecommerce and Media models to prepare a training dataset to be used with the AWS Personalize recommendation API and Shaped.ai CLI. Running this dbt package running on either of the above data warehouses will write/unload the models as csv files on to an AWS S3 bucket that AWS Personalize can access and import from, for training datasets to create the recommendations. The same buckets, generated as Parquet files, can be used for initial Datasets in Shaped.ai.

Currently, the media tracking from Snowplow does not provide a `click` event, which prevents Personalize from generating the Video On Demand's recommendation of `More Like X` and it is also why the `click` event types won't be available in our VOD's 'interactions' datasets.

Please refer to the [doc site](https://docs.snowplow.io/docs/modeling-your-data/modeling-your-data-with-dbt/) for a full breakdown of the package.

### Adapter Support

The snowplow-recommendations v0.0.1 package currently supports Snowflake and Databricks. 

|      Warehouse     |    dbt versions     | snowplow-recommendations version |
| :----------------: | :-----------------: | :------------------------------: |
|      Snowflake     |  >=1.0.0 to <2.0.0  |             0.1.0                |
|      Databricks    |  >=1.0.0 to <2.0.0  |             0.1.0                |

### Requirements

- A dataset of web events from the [Snowplow Javascript Tracker](https://docs.snowplow.io/docs/collecting-data/collecting-from-own-applications/) and familiarity with the [snowplow-ecommerce](https://hub.getdbt.com/snowplow/snowplow_ecommerce/latest/) and [snowplow-media-player](https://hub.getdbt.com/snowplow/snowplow_media_player/latest) dbt packages
- The `snowplow_ecommerce_product_interactions` and `snowplow_media_player_base` tables generated by the Snowplow dbt packages available in your warehouse

### Configuration & Operation

Please see below or refer to the [doc site](https://docs.snowplow.io/docs/modeling-your-data/modeling-your-data-with-dbt/) for details on how to configure and run the package and the python script that creates the final output table.

### Models

The package currently creates the required datasets to be used for AWS Personalize's recommendations for both the E-commerce and Video On Demand domains.

| Model                                           | Domain          | Description                                                                |
| ----------------------------------------------- | --------------- | -------------------------------------------------------------------------- |
| snowplow_recommendations_ecommerce_interactions | E-commerce      | The required training dataset containing the `View` and `Purchase` events. |
| snowplow_recommendations_ecommerce_users        | E-commerce      | The optional dataset containing users' metadata. |
| snowplow_recommendations_ecommerce_items        | E-commerce      | The optional dataset containing items' metadata. |
| snowplow_recommendations_media_interactions     | Video On Demand | The required training dataset containing the `Watch` events. |

### AWS Personalize

The models (datasets) this package builds will enable you to run the service for recommendations for the following use cases:
- Ecommerce:
  - Recommended For You
  - Most Viewed
  - Customers Who Viewed X Also Viewed
  - Best Sellers
  - Frequently Bought Together
- Video On Demand
  - Because You Watched X
  - Most Popular
  - Trending Now
  - Top Picks For You


The `interactions` datasets (for both domains) have the requirement that it must contain a minimum of 1000 interaction events from users (e.g. `watch` events for Video On Demand or `view` events for E-commerce) with at least two interactions for each of the event types from a minimum of 25 unique users. The recommended numbers are 50000 interactions from at least 1000 users with two or more interactions each. The two other E-commerce datasets of 'items' and 'users' are optional datasets containing categorical metadata that can help AWS Personalize identify underlying patterns relevent to users and items so that it may create more sensitive and relevant recommendation.

### Running

1. Ensure the setup steps have been completed above.
2. Follow the instructions in the README.md file at the root of the repository to set up AWS Personalize and the Flask app. To faciliate the automation of unloading the models as csv files to be used as training datasets by AWS Personalize, you will need to set up the necessary infrastructures on your cloud platform to allow these dbt models to be exported to AWS S3. The README file will have instructions on what the required steps are as well as the option in running the Terraform script to assist in setting this up.
3. You may wish to only run the models for a specific domain (or both) by enabling them in the project config file via:
    ```yaml
    models:
      snowplow_recommendations:
        +materialized: table
        ecommerce:
          enabled: true
        media:
          enabled: true
    ```

4. You may need to update some variables in your `dbt_project.yml` file:
   - `tables_to_export`: When a domain type is enabled in the config file then all the models for that domain will be built, but you may list which tables (models) to be exported to S3 with this variable here. Enter the name of the model in this array if you'd like a table to be exported to S3 to be trained by AWS Personalize (note that the 'interaction' models are required datasets but the 'items' and 'users' datasets are optional).
   - `snowflake_stage_name`: This will be the name of the external Stage in your Snowflake account to load data to AWS S3. If you used Terraform to create this stage then the name can be found in the TF variable files.
   - `external_catalog`: This is the name of the external catalog on your Databricks account. In order to create external tables the query must be executed from an external catalog. If you used Terraform to create this stage then the name can be found in the TF variable files.
   - `s3_bucket`: This is the S3 path (i.e. `s3://<bucket name>/`) for which your Databricks' external location is configured to. If you used Terraform to create this stage then the name can be found in the TF variable files.

    The other variables behave similarly to all the other Snowplow dbt packages and their configurable variables for running the models.

5. Run `dbt deps`, then `dbt run`

### Extensibility

Read the [dbt docs regarding Git packages](https://docs.getdbt.com/docs/build/packages#git-packages) for more information on how to extend this project to fit your needs.

# Join the Snowplow community

We welcome all ideas, questions and contributions!

For support requests, please use our [community support forum](https://community.snowplow.io/).

If you find a bug, please report an issue on GitHub.

# Copyright and license

The snowplow-recommendation package is Copyright 2023-current Snowplow Analytics Ltd.

Licensed under the [Snowplow Personal and Academic License][license] (the "License");
you may not use this software except in compliance with the License.

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

[license]: https://docs.snowplow.io/personal-and-academic-license-1.0/
[license-image]: https://img.shields.io/badge/license-SPAL-blue

[website]: https://snowplow.io/
[snowplow]: https://github.com/snowplow/snowplow
[docs]: https://docs.snowplow.io/

[release-image]: https://img.shields.io/github/v/release/snowplow/dbt-snowplow-recommendations?sort=semver
[releases]: https://github.com/snowplow/dbt-snowplow-recommendations/releases

[tracker-classification]: https://docs.snowplow.io/docs/collecting-data/collecting-from-own-applications/tracker-maintenance-classification/
[early-release]: https://img.shields.io/static/v1?style=flat&label=Snowplow&message=Early%20Release&color=014477&labelColor=9ba0aa&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAeFBMVEVMaXGXANeYANeXANZbAJmXANeUANSQAM+XANeMAMpaAJhZAJeZANiXANaXANaOAM2WANVnAKWXANZ9ALtmAKVaAJmXANZaAJlXAJZdAJxaAJlZAJdbAJlbAJmQAM+UANKZANhhAJ+EAL+BAL9oAKZnAKVjAKF1ALNBd8J1AAAAKHRSTlMAa1hWXyteBTQJIEwRgUh2JjJon21wcBgNfmc+JlOBQjwezWF2l5dXzkW3/wAAAHpJREFUeNokhQOCA1EAxTL85hi7dXv/E5YPCYBq5DeN4pcqV1XbtW/xTVMIMAZE0cBHEaZhBmIQwCFofeprPUHqjmD/+7peztd62dWQRkvrQayXkn01f/gWp2CrxfjY7rcZ5V7DEMDQgmEozFpZqLUYDsNwOqbnMLwPAJEwCopZxKttAAAAAElFTkSuQmCC
[unsupported]: https://img.shields.io/static/v1?style=flat&label=Snowplow&message=Unsupported&color=24292e&labelColor=lightgrey&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAeFBMVEVMaXGXANeYANeXANZbAJmXANeUANSQAM+XANeMAMpaAJhZAJeZANiXANaXANaOAM2WANVnAKWXANZ9ALtmAKVaAJmXANZaAJlXAJZdAJxaAJlZAJdbAJlbAJmQAM+UANKZANhhAJ+EAL+BAL9oAKZnAKVjAKF1ALNBd8J1AAAAKHRSTlMAa1hWXyteBTQJIEwRgUh2JjJon21wcBgNfmc+JlOBQjwezWF2l5dXzkW3/wAAAHpJREFUeNokhQOCA1EAxTL85hi7dXv/E5YPCYBq5DeN4pcqV1XbtW/xTVMIMAZE0cBHEaZhBmIQwCFofeprPUHqjmD/+7peztd62dWQRkvrQayXkn01f/gWp2CrxfjY7rcZ5V7DEMDQgmEozFpZqLUYDsNwOqbnMLwPAJEwCopZxKttAAAAAElFTkSuQmCC
[maintained]: https://img.shields.io/static/v1?style=flat&label=Snowplow&message=Maintained&color=9e62dd&labelColor=9ba0aa&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAeFBMVEVMaXGXANeYANeXANZbAJmXANeUANSQAM+XANeMAMpaAJhZAJeZANiXANaXANaOAM2WANVnAKWXANZ9ALtmAKVaAJmXANZaAJlXAJZdAJxaAJlZAJdbAJlbAJmQAM+UANKZANhhAJ+EAL+BAL9oAKZnAKVjAKF1ALNBd8J1AAAAKHRSTlMAa1hWXyteBTQJIEwRgUh2JjJon21wcBgNfmc+JlOBQjwezWF2l5dXzkW3/wAAAHpJREFUeNokhQOCA1EAxTL85hi7dXv/E5YPCYBq5DeN4pcqV1XbtW/xTVMIMAZE0cBHEaZhBmIQwCFofeprPUHqjmD/+7peztd62dWQRkvrQayXkn01f/gWp2CrxfjY7rcZ5V7DEMDQgmEozFpZqLUYDsNwOqbnMLwPAJEwCopZxKttAAAAAElFTkSuQmCC
[actively-maintained]: https://img.shields.io/static/v1?style=flat&label=Snowplow&message=Actively%20Maintained&color=6638b8&labelColor=9ba0aa&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAeFBMVEVMaXGXANeYANeXANZbAJmXANeUANSQAM+XANeMAMpaAJhZAJeZANiXANaXANaOAM2WANVnAKWXANZ9ALtmAKVaAJmXANZaAJlXAJZdAJxaAJlZAJdbAJlbAJmQAM+UANKZANhhAJ+EAL+BAL9oAKZnAKVjAKF1ALNBd8J1AAAAKHRSTlMAa1hWXyteBTQJIEwRgUh2JjJon21wcBgNfmc+JlOBQjwezWF2l5dXzkW3/wAAAHpJREFUeNokhQOCA1EAxTL85hi7dXv/E5YPCYBq5DeN4pcqV1XbtW/xTVMIMAZE0cBHEaZhBmIQwCFofeprPUHqjmD/+7peztd62dWQRkvrQayXkn01f/gWp2CrxfjY7rcZ5V7DEMDQgmEozFpZqLUYDsNwOqbnMLwPAJEwCopZxKttAAAAAElFTkSuQmCC
